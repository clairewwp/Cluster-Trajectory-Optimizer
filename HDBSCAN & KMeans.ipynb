{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c88b9a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# conda install -c conda-forge hdbscan\n",
    "# pip3 install hdbscan\n",
    "# pip3 install joblib==1.1.0 ##otherwise, error occurs:__init__() got an unexpected keyword argument 'cachedir'\n",
    "import pandas as pd\n",
    "df= pd.read_csv('boundary_corelation.csv')## import the correlation matrix\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ec66d3c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import hdbscan\n",
    "from sklearn.datasets import make_blobs\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "82cd948d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new=pd.DataFrame()\n",
    "df_new['pathid']=df.index+1\n",
    "df_new['pathid']=df_new['pathid'].replace([63],['Clusters_found'])\n",
    "df_new = df_new.append({'pathid':'Noise_count'},ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "316adaf4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pathid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>Clusters_found</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>Noise_count</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            pathid\n",
       "59              60\n",
       "60              61\n",
       "61              62\n",
       "62  Clusters_found\n",
       "63     Noise_count"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b02d3d50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== HDBSCAN ==========\n",
      "[ 7  4  5  6  3  4  3  4  6  0  7  7  0  3  3  4  4  5  5 -1  2  6 -1  8\n",
      " -1  8  7 -1  7  1  1 -1  0  3  3 -1  3  4  5  5  5 -1 -1  2  2 -1 -1 -1\n",
      " -1  7 -1 -1  1 -1  8 -1  3  4  4 -1  7  8]\n",
      "===============================\n",
      "Minimun cluster size: 2\n",
      "Identified clusters: 9 =>\n",
      " [[0 3]\n",
      " [1 3]\n",
      " [2 3]\n",
      " [3 8]\n",
      " [4 8]\n",
      " [5 6]\n",
      " [6 3]\n",
      " [7 7]\n",
      " [8 4]]\n",
      "Identifide noise 17\n",
      "===============================\n",
      "\n",
      "[ 3  1  2  4  0  1  0  1  4 -1  3  3 -1  0  0  1  1  2  2 -1 -1  4 -1  3\n",
      "  3  3  3  3  3 -1 -1 -1 -1  0  0 -1  0  1  2  2 -1 -1 -1 -1 -1 -1 -1 -1\n",
      "  4  3 -1 -1 -1 -1  3  3  0  1  1 -1  3  3]\n",
      "===============================\n",
      "Minimun cluster size: 3\n",
      "Identified clusters: 5 =>\n",
      " [[ 0  8]\n",
      " [ 1  8]\n",
      " [ 2  5]\n",
      " [ 3 14]\n",
      " [ 4  4]]\n",
      "Identifide noise 23\n",
      "===============================\n",
      "\n",
      "[ 2  0  3 -1  1  0  1  0  3 -1  2  2 -1  1  1  0  0  3  3 -1 -1  3 -1  2\n",
      "  2  2  2  2  2 -1 -1 -1 -1  1  1 -1  1  0  3  3  3 -1 -1 -1 -1 -1 -1 -1\n",
      "  2  2 -1 -1 -1 -1  2 -1  1  0  0 -1  2  2]\n",
      "===============================\n",
      "Minimun cluster size: 4\n",
      "Identified clusters: 4 =>\n",
      " [[ 0  8]\n",
      " [ 1  8]\n",
      " [ 2 14]\n",
      " [ 3  8]]\n",
      "Identifide noise 24\n",
      "===============================\n",
      "\n",
      "[ 2  0  3  3  1  0  1  0 -1 -1  2  2 -1  1  1  0  0  3  3 -1 -1  3 -1  2\n",
      "  2  2  2  2  2 -1 -1 -1 -1  1  1 -1  1  0  3  3  3 -1 -1 -1 -1 -1 -1 -1\n",
      "  2  2 -1 -1 -1 -1  2 -1  1  0  0 -1  2  2]\n",
      "===============================\n",
      "Minimun cluster size: 5\n",
      "Identified clusters: 4 =>\n",
      " [[ 0  8]\n",
      " [ 1  8]\n",
      " [ 2 14]\n",
      " [ 3  8]]\n",
      "Identifide noise 24\n",
      "===============================\n",
      "\n",
      "[ 0  1  0  0  2  1  2  1  0 -1  0  0 -1  2  2  1  1  0  0 -1 -1  0  0  0\n",
      "  0  0  0  0  0 -1 -1 -1 -1  2  2 -1  2  1  0 -1  0  0 -1 -1 -1  0  0 -1\n",
      "  0  0  0  0 -1 -1  0  0  2  1  1 -1  0  0]\n",
      "===============================\n",
      "Minimun cluster size: 6\n",
      "Identified clusters: 3 =>\n",
      " [[ 0 29]\n",
      " [ 1  8]\n",
      " [ 2  8]]\n",
      "Identifide noise 17\n",
      "===============================\n",
      "\n",
      "[ 0  1 -1 -1  1  1  1  1  0 -1  0  0 -1  1  1  1  1 -1  0 -1  1  0 -1  0\n",
      "  0  0  0  0  0  1 -1 -1 -1  1  1 -1  1  1  0 -1  0 -1  1  1 -1  0  0 -1\n",
      "  0  0  0  0 -1 -1  0  0  1  1  1 -1  0  0]\n",
      "===============================\n",
      "Minimun cluster size: 8\n",
      "Identified clusters: 2 =>\n",
      " [[ 0 24]\n",
      " [ 1 20]]\n",
      "Identifide noise 18\n",
      "===============================\n",
      "\n",
      "[ 0  1 -1 -1  1  1  1  1  0 -1  0  0 -1  1  1  1  1 -1 -1 -1  1  0 -1  0\n",
      "  0  0  0  0  0 -1 -1 -1 -1  1  1 -1  1  1  0 -1 -1 -1  1  1 -1  0  0 -1\n",
      "  0  0  0  0 -1 -1  0  0  1  1  1 -1  0  0]\n",
      "===============================\n",
      "Minimun cluster size: 10\n",
      "Identified clusters: 2 =>\n",
      " [[ 0 22]\n",
      " [ 1 19]]\n",
      "Identifide noise 21\n",
      "===============================\n",
      "\n",
      "time take = 0.10378789901733398\n"
     ]
    }
   ],
   "source": [
    "min_cluster_size=[2,3,4,5,6,8,10]\n",
    "start_time = time.time()\n",
    "print(\"========== HDBSCAN ==========\")\n",
    "for mins in min_cluster_size:\n",
    "    df= pd.read_csv('boundary_corelation.csv')\n",
    "    ##drop the index 62 for both column and row as the last path is not needed\n",
    "    df=df.drop('62',axis=1,inplace=False)\n",
    "    df=df.drop(62)\n",
    "    ##run HDBSCAN \n",
    "    db= hdbscan.HDBSCAN(min_cluster_size=mins).fit(df)\n",
    "    labels=db.labels_\n",
    "    labelx=labels\n",
    "\n",
    "    ##print the result of HDBSCAN\n",
    "    print(labels[0::])\n",
    "    print(\"===============================\")\n",
    "    print('Minimun cluster size:',mins)\n",
    "    #print the total number of clusters (including noise : -1)\n",
    "    cluster=np.unique(labels)\n",
    "    num_cluster=len(cluster)-1\n",
    "    modified_clusters = np.delete(labels, np.where(labels == -1))\n",
    "    frequency=np.array(np.unique(modified_clusters, return_counts=True)).T\n",
    "    print('Identified clusters:',(len(cluster)-1),\"=>\\n\",frequency)\n",
    "    name= 'label_'+str(mins)\n",
    "    ##counting the noise number in each set\n",
    "    noise= list(labels).count(-1)\n",
    "    labels=np.append(labels,num_cluster)\n",
    "    labels=np.append(labels,noise)\n",
    "    df_new[name]=labels\n",
    "    print(\"Identifide noise\",noise)\n",
    "    print(\"===============================\\n\")\n",
    "end_time = time.time()\n",
    "print(\"time take =\", end_time - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "be8ebd08",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new.to_csv('total_HDBSCAN.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "83542abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df= pd.read_csv('boundary_corelation.csv')## import the correlation matrix\n",
    "df_new=pd.DataFrame()\n",
    "df_new['pathid']=df.index+1\n",
    "df_new['pathid']=df_new['pathid'].replace([63],['Clusters_found'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8aeaa94b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pathid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>Clusters_found</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            pathid\n",
       "58              59\n",
       "59              60\n",
       "60              61\n",
       "61              62\n",
       "62  Clusters_found"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7e509c73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== KMeans ==========\n",
      "[2 1 0 2 1 1 1 1 2 0 2 2 0 1 1 1 1 0 0 0 1 2 0 2 2 2 2 2 2 1 1 0 0 1 1 0 1\n",
      " 1 0 0 0 0 1 1 1 0 0 0 2 2 2 2 1 0 2 2 1 1 1 0 2 2]\n",
      "===============================\n",
      "Number of clusters: 3\n",
      "Identified clusters: 2 =>\n",
      " [[ 0 19]\n",
      " [ 1 23]\n",
      " [ 2 20]]\n",
      "===============================\n",
      "\n",
      "[0 1 3 3 1 1 1 1 0 2 0 0 2 1 1 1 1 3 3 2 1 3 3 0 0 0 0 0 0 1 1 2 2 1 1 2 1\n",
      " 1 3 3 3 2 1 1 1 3 3 3 0 0 0 0 1 2 0 0 1 1 1 2 0 0]\n",
      "===============================\n",
      "Number of clusters: 4\n",
      "Identified clusters: 3 =>\n",
      " [[ 0 18]\n",
      " [ 1 23]\n",
      " [ 2  9]\n",
      " [ 3 12]]\n",
      "===============================\n",
      "\n",
      "[1 0 2 2 0 0 0 0 1 3 1 1 3 0 0 0 0 2 2 4 4 2 2 1 1 1 1 1 1 4 4 3 3 0 0 4 0\n",
      " 0 2 2 2 2 4 4 4 2 2 2 1 1 1 1 4 2 1 1 0 0 0 4 1 1]\n",
      "===============================\n",
      "Number of clusters: 5\n",
      "Identified clusters: 4 =>\n",
      " [[ 0 16]\n",
      " [ 1 18]\n",
      " [ 2 14]\n",
      " [ 3  4]\n",
      " [ 4 10]]\n",
      "===============================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "num_clusters=[3,4,5]\n",
    "start_time = time.time()\n",
    "print(\"========== KMeans ==========\")\n",
    "for num in num_clusters:\n",
    "    df= pd.read_csv('boundary_corelation.csv')\n",
    "    ##drop the index 62 for both column and row as the last path is not needed\n",
    "    df=df.drop('62',axis=1,inplace=False)\n",
    "    df=df.drop(62)\n",
    "    ##run Kmeans \n",
    "    db= KMeans(n_clusters=num, random_state=0).fit(df)\n",
    "    labels=db.labels_\n",
    "    labelx=labels\n",
    "\n",
    "    ##print the result of Kmeans\n",
    "    print(labels[0::])\n",
    "    print(\"===============================\")\n",
    "    #print the minimun support used in the set\n",
    "    print('Number of clusters:',num)\n",
    "    #print the total number of clusters (including noise : -1)\n",
    "    cluster=np.unique(labels)\n",
    "    num_cluster=len(cluster)-1\n",
    "    modified_clusters = np.delete(labels, np.where(labels == -1))\n",
    "    frequency=np.array(np.unique(modified_clusters, return_counts=True)).T\n",
    "    print('Identified clusters:',(len(cluster)-1),\"=>\\n\",frequency)\n",
    "    name= 'label_'+str(num)\n",
    "    labels=np.append(labels,num_cluster)\n",
    "    df_new[name]=labels\n",
    "    print(\"===============================\\n\")\n",
    "end_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6e52649c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new.to_csv('total_KMeans_output.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76483359",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
